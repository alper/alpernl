---
_g_feedback_shortcode_atts_b271cc152e89d9e9ce0f56c63b7d3429d0726019:
  block_template: null
  block_template_part: null
  className: null
  customThankyou: ""
  customThankyouHeading: Your message has been sent
  customThankyouMessage: Thank you for your submission!
  customThankyouRedirect: ""
  hiddenFields: null
  id: 18059
  jetpackCRM: true
  postToUrl: null
  salesforceData: null
  show_subject: "no"
  subject: '[alper.nl] '
  submit_button_text: Submit
  to: alper@alper.nl
  widget: 0
_g_feedback_shortcode_b271cc152e89d9e9ce0f56c63b7d3429d0726019: |-
  [contact-field label="Name" type="name"  required="true" /]
  				[contact-field label="Email" type="email" required="true" /]
  				[contact-field label="Website" type="url" /]
  				[contact-field label="Message" type="textarea" /]
_wpas_done_all: "1"
author: alper
categories:
  - english
  - science
  - software-engineering
date: "2025-02-08T20:49:25+00:00"
guid: https://alper.nl/dingen/?p=18059
parent_post_id: null
post_id: "18059"
title: ""
aliases:
  - /dingen/2025/02/18059/

---
> LLMs are fundamentally matching the patterns they’ve seen, and their abilities are constrained by mathematical boundaries. Embedding tricks and chain-of-thought prompting simply extends their ability to do more sophisticated pattern matching. The mathematical results imply that you can always find compositional tasks whose complexity lies beyond a given system’s abilities.

LLMs are still very useful in a bunch of domains but here's an article explaining (from a [paper with a novel bound](https://arxiv.org/pdf/2412.02975) on computational complexity) why improvements in reasoning seem to have run out of steam.

https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/

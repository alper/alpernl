---
_last_editor_used_jetpack: block-editor
_oembed_24eca338e177d0abf3a227c7b9026db0: '{{unknown}}'
_oembed_afa15f5636908f922f04cf8d620d39a7: <iframe class="wp-embedded-content" sandbox="allow-scripts" security="restricted" src="https://hachyderm.io/@inthehands/109892145569287793/embed#?secret=uuhtKWgkCr" data-secret="uuhtKWgkCr" width="660" height="990"></iframe>
_oembed_time_afa15f5636908f922f04cf8d620d39a7: "1676914153"
_wpas_done_all: "1"
author: alper
categories:
  - english
  - software-engineering
date: "2023-02-20T17:29:19+00:00"
guid: https://alper.nl/dingen/?p=17083
parent_post_id: null
post_id: "17083"
title: ""
aliases:
  - /dingen/2023/02/17083/

---
A result that generalizes prompt hacking and would point towards most deep learning AIs are exploitable (and proably trivially so).

https://hachyderm.io/@inthehands/109892145569287793
